{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c7fd5b-99c0-4ec6-8c1a-bc724a8c1263",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20976841-f12e-4575-9e65-df53e3096ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import fireducks.pandas as pd\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import (\n",
    "                                    cross_val_score,\n",
    "                                    RandomizedSearchCV,\n",
    "                                    GridSearchCV, \n",
    "                                    train_test_split,\n",
    "                                    StratifiedKFold\n",
    "                                    )\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from ml_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bfede60-9124-4c0f-a243-684e52391db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "fs = s3fs.S3FileSystem(\n",
    "            client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"},\n",
    "            key=os.environ[\"Accesskey\"],\n",
    "            secret=os.environ[\"Secretkey\"],\n",
    "            token=os.environ[\"Token\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfefd20-d69c-46de-8d59-67096ab8b371",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5e87e5-7b6a-4f1d-8fa1-d429f5cbdc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_text</th>\n",
       "      <th>sol</th>\n",
       "      <th>clean_phrase_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>* Aider à la mise en place de l évènement Shar...</td>\n",
       "      <td>0</td>\n",
       "      <td>aider mise place évènemer shareplan envoi rapp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* Comprendre le métier des achats * Comment or...</td>\n",
       "      <td>0</td>\n",
       "      <td>comprendre métier achat comment organiser appe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* Fendre du bois en forêt au merlin manuelleme...</td>\n",
       "      <td>0</td>\n",
       "      <td>fendre boi forêt merlin manuellemer débarder b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 jours au CDI , 1 jour en arts plastiques , 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>2 jour cdi 1 jour art plastique 1 jour musiqu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 jours au sein du Bureau des affaires institu...</td>\n",
       "      <td>1</td>\n",
       "      <td>4 jour sein bureau affaire institutionnel fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with fs.open(\"elissamim/text_classification_men/data/stages-votes.json\", \"r\") as file:\n",
    "    df = pd.read_json(file)\n",
    "\n",
    "df = df.groupby(\"phrase_text\", as_index = False)[\"sol\"].apply(lambda x: x.mode().iloc[0])\n",
    "df[\"sol\"]=df[\"sol\"].apply(lambda x: 1 if x == \"ok\" else 0)\n",
    "df[\"clean_phrase_text\"] = df[\"phrase_text\"].apply(lambda x: nltk_text_preprocessing(x, True))\n",
    "df = df[df[\"clean_phrase_text\"] != \"\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e3346-d25a-4e73-a41d-2b4eb7cd41aa",
   "metadata": {},
   "source": [
    "# Model selection (static embedding (sparse or dense) + classification algorithm) with grid search and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95cca3e-4f24-4689-99a4-5bd302a7a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"clean_phrase_text\"]\n",
    "y = df[\"sol\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071f8ae2-9587-4608-a156-ba67eb9896c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_texts = [text.split() for text in X_train]\n",
    "word2vec_model = Word2Vec(sentences = tokenized_texts,\n",
    "                         vector_size = 100,\n",
    "                         window = 5,\n",
    "                         min_count = 1,\n",
    "                         workers = 4,\n",
    "                         seed = 42)\n",
    "fasttext_model = FastText(sentences = tokenized_texts,\n",
    "                         vector_size = 100,\n",
    "                         window = 5,\n",
    "                         min_count = 1,\n",
    "                         workers = 4,\n",
    "                         seed = 42)\n",
    "\n",
    "static_embedding_models = {\n",
    "    # Sparse embeddings\n",
    "    \"Bag of Words\":CountVectorizer(),\n",
    "    \"TF\":TfidfVectorizer(use_idf=False),\n",
    "    \"TF-IDF\":TfidfVectorizer(),\n",
    "    # Dense embeddings\n",
    "    \"Word2Vec\": MeanEmbeddingVectorizer(model=word2vec_model),\n",
    "    \"FastText\": MeanEmbeddingVectorizer(model=fasttext_model)\n",
    "}\n",
    "\n",
    "classification_models = {\n",
    "    \"Logistic Regression\":LogisticRegression(),\n",
    "    \"Random Forest\":RandomForestClassifier(),\n",
    "    \"Linear SVM\":SVC(kernel=\"linear\", probability=True),\n",
    "    \"Multinomial Naive Bayes\":MultinomialNB(),\n",
    "    \"XGBoost\":XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5ca4b7-c0c2-42ae-9415-d934ce326cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    \"Bag of Words\" : {\n",
    "        \"feature_extraction__ngram_range\":[(1,1), (1,2), (2,2)],\n",
    "        \"feature_extraction__max_df\":[.7, .9, 1],\n",
    "        \"feature_extraction__min_df\":[.001, .01, .1],\n",
    "        \"feature_extraction__max_features\":[10, 100, 1000, 10000],\n",
    "        \"feature_extraction__binary\":[True, False]\n",
    "    },\n",
    "    \"TF\" : {\n",
    "        \"feature_extraction__max_df\":[.7, .8, .9, 1],\n",
    "        \"feature_extraction__min_df\":[.001, .01, .1],\n",
    "        \"feature_extraction__norm\":[\"l1\", \"l2\", None],\n",
    "        \"feature_extraction__sublinear_tf\":[True, False],\n",
    "        \"feature_extraction__max_features\":[10, 100, 1000, 10000],\n",
    "        \"feature_extraction__ngram_range\":[(1,1), (1,2), (2,2)]\n",
    "    },\n",
    "    \"TF-IDF\" : {\n",
    "        \"feature_extraction__max_df\":[.7, .8, .9, 1],\n",
    "        \"feature_extraction__min_df\":[.001, .01, .1],\n",
    "        \"feature_extraction__norm\":[\"l1\", \"l2\", None],\n",
    "        \"feature_extraction__sublinear_tf\":[True, False],\n",
    "        \"feature_extraction__max_features\":[10, 100, 1000, 10000],\n",
    "        \"feature_extraction__ngram_range\":[(1,1), (1,2), (2,2)]\n",
    "    },\n",
    "    \"Logistic Regression\":{\n",
    "        \"classifier__C\":[.001, .01, .1, 1, 10, 100],\n",
    "        \"classifier__penalty\":[\"l2\"],\n",
    "        \"classifier__solver\":[\"lbfgs\"]\n",
    "    },\n",
    "    \"Random Forest\":{\n",
    "        \"classifier__n_estimators\":[100,300,500],\n",
    "        \"classifier__max_depth\":[None, 10, 20, 50],\n",
    "        \"classifier__min_samples_split\": [2, 5, 10],\n",
    "        \"classifier__min_samples_leaf\":[1, 2, 5, 10],\n",
    "        \"classifier__max_features\":[\"sqrt\", \"log2\", None],\n",
    "        \"classifier__bootstrap\":[True, False]\n",
    "    },\n",
    "    \"Linear SVM\":{\n",
    "        \"classifier__C\":[.001, .01, .1, 1, 10, 100]\n",
    "    },\n",
    "    \"Multinomial Naive Bayes\":{\n",
    "        \"classifier__alpha\":[.0001, .001, .01, .1, 1, 10],\n",
    "        \"classifier__fit_prior\":[True, False]\n",
    "    },\n",
    "    \"XGBoost\":{\n",
    "        \"classifier__n_estimators\":[100, 200, 300, 500],\n",
    "        \"classifier__max_depth\":[3, 5, 7, 10],\n",
    "        \"classifier__learning_rate\":[.01, .05, .1, .3],\n",
    "        \"classifier__subsample\":[.5, .7, .8, 1],\n",
    "        \"classifier__colsample_bytree\":[.5, .7, .8, 1],\n",
    "        \"classifier__gamma\":[0, .1, .5, 1],\n",
    "        \"classifier__reg_alpha\":[0, .01, .1, 1],\n",
    "        \"classifier__reg_lambda\":[.1, 1, 10]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93deb4a-83b1-4554-9260-e967f9dbec38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Static embeddings:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Classification algorithms:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Classification algorithms:  20%|██        | 1/5 [00:04<00:17,  4.43s/it]\u001b[A\n",
      "Classification algorithms:  40%|████      | 2/5 [00:12<00:18,  6.32s/it]\u001b[A\n",
      "Classification algorithms:  60%|██████    | 3/5 [00:38<00:31, 15.67s/it]\u001b[A\n",
      "Classification algorithms:  80%|████████  | 4/5 [00:40<00:10, 10.04s/it]\u001b[A/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "\n",
      "Classification algorithms: 100%|██████████| 5/5 [00:43<00:00,  8.80s/it]\u001b[A\n",
      "Static embeddings:  20%|██        | 1/5 [00:44<02:56, 44.02s/it]\n",
      "Classification algorithms:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Classification algorithms:  20%|██        | 1/5 [00:01<00:06,  1.64s/it]\u001b[A\n",
      "Classification algorithms:  40%|████      | 2/5 [00:11<00:19,  6.35s/it]\u001b[A\n",
      "Classification algorithms:  60%|██████    | 3/5 [00:14<00:09,  4.96s/it]\u001b[A\n",
      "Classification algorithms:  80%|████████  | 4/5 [00:15<00:03,  3.53s/it]\u001b[A/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:19:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:20:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "\n",
      "Classification algorithms: 100%|██████████| 5/5 [00:19<00:00,  3.83s/it]\u001b[A\n",
      "Static embeddings:  40%|████      | 2/5 [01:03<01:28, 29.39s/it]\n",
      "Classification algorithms:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Classification algorithms:  20%|██        | 1/5 [00:01<00:05,  1.49s/it]\u001b[A\n",
      "Classification algorithms:  40%|████      | 2/5 [00:12<00:20,  6.88s/it]\u001b[A\n",
      "Classification algorithms:  60%|██████    | 3/5 [01:11<01:01, 30.73s/it]\u001b[A\n",
      "Classification algorithms:  80%|████████  | 4/5 [01:13<00:19, 19.39s/it]\u001b[A/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:21:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "\n",
      "Classification algorithms: 100%|██████████| 5/5 [01:23<00:00, 16.66s/it]\u001b[A\n",
      "Static embeddings:  60%|██████    | 3/5 [02:26<01:48, 54.00s/it]\n",
      "Classification algorithms:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:02\u001b[0mmmm\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "Collecting fr-core-news-sm==3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "Collecting fr-core-news-sm==3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification algorithms:  20%|██        | 1/5 [00:55<03:41, 55.45s/it]\u001b[A[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification algorithms:  40%|████      | 2/5 [03:56<06:27, 129.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification algorithms:  60%|██████    | 3/5 [12:23<10:03, 301.80s/it]\u001b[A/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/16.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/16.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:02\u001b[0mmm\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/16.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0mmm"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:02\u001b[0mm\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m13.1/16.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:33:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:03] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:03] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:03] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:03] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:09] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:09] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/conda/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [15:34:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744352472081/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "\n",
      "Classification algorithms: 100%|██████████| 5/5 [13:16<00:00, 159.29s/it]\u001b[A\n",
      "Static embeddings:  80%|████████  | 4/5 [15:42<05:47, 347.12s/it]\n",
      "Classification algorithms:   0%|          | 0/5 [00:18<?, ?it/s]\u001b[A\n",
      "Static embeddings:  80%|████████  | 4/5 [16:01<04:00, 240.25s/it]\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 159, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.12/site-packages/joblib/externals/loky/backend/reduction.py\", line 215, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"/opt/conda/lib/python3.12/site-packages/joblib/externals/loky/backend/reduction.py\", line 208, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"/opt/conda/lib/python3.12/site-packages/joblib/externals/cloudpickle/cloudpickle.py\", line 1245, in dump\n    return super().dump(obj)\n           ^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.12/site-packages/joblib/_memmapping_reducer.py\", line 451, in __call__\n    for dumped_filename in dump(a, filename):\n                           ^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.12/site-packages/joblib/numpy_pickle.py\", line 553, in dump\n    NumpyPickler(f, protocol=protocol).dump(value)\n  File \"/opt/conda/lib/python3.12/pickle.py\", line 484, in dump\n    self.save(obj)\n  File \"/opt/conda/lib/python3.12/site-packages/joblib/numpy_pickle.py\", line 352, in save\n    wrapper.write_array(obj, self)\n  File \"/opt/conda/lib/python3.12/site-packages/joblib/numpy_pickle.py\", line 134, in write_array\n    pickler.file_handle.write(chunk.tobytes('C'))\nOSError: [Errno 28] No space left on device\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mPicklingError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     33\u001b[39m selected_params_grid = {\n\u001b[32m     34\u001b[39m     **params_grid.get(embedding_name, {}),\n\u001b[32m     35\u001b[39m     **params_grid.get(classification_name, {})\n\u001b[32m     36\u001b[39m }\n\u001b[32m     38\u001b[39m grid_search = RandomizedSearchCV(\n\u001b[32m     39\u001b[39m     pipeline,\n\u001b[32m     40\u001b[39m     param_distributions=selected_params_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     n_iter = \u001b[32m20\u001b[39m\n\u001b[32m     46\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m score = grid_search.best_score_\n\u001b[32m     51\u001b[39m dict_params[embedding_name][classification_name] = grid_search.best_params_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/joblib/parallel.py:1754\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1748\u001b[39m \n\u001b[32m   1749\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1752\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1755\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1757\u001b[39m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/joblib/parallel.py:1789\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1785\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1789\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/joblib/parallel.py:745\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    739\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    742\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    743\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    744\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/joblib/parallel.py:763\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    762\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mPicklingError\u001b[39m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "dict_scores, dict_params = {}, {}\n",
    "\n",
    "for embedding_name, embedding_model in tqdm(static_embedding_models.items(),\n",
    "                                           desc=\"Static embeddings\"):\n",
    "\n",
    "    dict_scores[embedding_name], dict_params[embedding_name] = {}, {}\n",
    "    \n",
    "    for classification_name, classification_model in tqdm(classification_models.items(),\n",
    "                                                         desc=\"Classification algorithms\"):\n",
    "\n",
    "        # Multinomial NB is not suited for dense vectors\n",
    "        if embedding_name in [\"Word2Vec\", \"FastText\"] and classification_name == \"Multinomial Naive Bayes\":\n",
    "            continue\n",
    "\n",
    "        steps = [(\"feature_extraction\", embedding_model)]\n",
    "\n",
    "        # For Logistic Regression and Linear SVM, and for dense embeddings, add standardisation\n",
    "        if embedding_name in [\"Word2Vec\", \"FastText\"] and classification_name in [\"Logistic Regression\", \"Linear SVM\"]:\n",
    "            steps.append((\"standardisation\", StandardScaler()))\n",
    "\n",
    "        steps.append((\"classifier\", classification_model))\n",
    "\n",
    "        pipeline = Pipeline(steps)\n",
    "\n",
    "        # We compute scores using Grid Search on the parameter grid to do model selection with best\n",
    "        # hyperparameters\n",
    "        cv = StratifiedKFold(n_splits=5, \n",
    "                                 shuffle = True, \n",
    "                                 random_state=42)\n",
    "        \n",
    "        if (embedding_name in params_grid) or (classification_name in params_grid):\n",
    "\n",
    "            selected_params_grid = {\n",
    "                **params_grid.get(embedding_name, {}),\n",
    "                **params_grid.get(classification_name, {})\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                grid_search = RandomizedSearchCV(\n",
    "                    pipeline,\n",
    "                    param_distributions=selected_params_grid,\n",
    "                    cv=cv,\n",
    "                    scoring=\"accuracy\",\n",
    "                    n_jobs=-1,\n",
    "                    verbose=0,\n",
    "                    n_iter = 20\n",
    "                )\n",
    "            except PicklingError:\n",
    "                grid_search = RandomizedSearchCV(\n",
    "                    pipeline,\n",
    "                    param_distributions=selected_params_grid,\n",
    "                    cv=cv,\n",
    "                    scoring=\"accuracy\",\n",
    "                    n_jobs=1,\n",
    "                    verbose=0,\n",
    "                    n_iter = 20\n",
    "                )\n",
    "            \n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            score = grid_search.best_score_\n",
    "            dict_params[embedding_name][classification_name] = grid_search.best_params_\n",
    "\n",
    "        else:\n",
    "\n",
    "            scores = cross_val_score(\n",
    "                pipeline,\n",
    "                X_train, \n",
    "                y_train,\n",
    "                cv=cv,\n",
    "                scoring=\"accuracy\"\n",
    "            )\n",
    "\n",
    "            score = np.mean(scores)\n",
    "            \n",
    "        dict_scores[embedding_name][classification_name] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781ce367-f698-44b5-a652-f566ef78a11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5f67073-b957-4b9d-bf65-5e37e5677992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Logistic Regression'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8527d47-bd23-43a4-8d50-7ba0327a0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bag of Words': {'Linear SVM': 0.6669811320754716,\n",
      "                  'Logistic Regression': 0.6839622641509434,\n",
      "                  'Multinomial Naive Bayes': 0.679245283018868,\n",
      "                  'Random Forest': 0.690566037735849,\n",
      "                  'XGBoost': 0.689622641509434},\n",
      " 'FastText': {},\n",
      " 'TF': {'Linear SVM': 0.6867924528301887,\n",
      "        'Logistic Regression': 0.6528301886792454,\n",
      "        'Multinomial Naive Bayes': 0.6820754716981131,\n",
      "        'Random Forest': 0.6783018867924528,\n",
      "        'XGBoost': 0.6962264150943396},\n",
      " 'TF-IDF': {'Linear SVM': 0.6839622641509433,\n",
      "            'Logistic Regression': 0.6886792452830189,\n",
      "            'Multinomial Naive Bayes': 0.630188679245283,\n",
      "            'Random Forest': 0.6877358490566038,\n",
      "            'XGBoost': 0.6547169811320754},\n",
      " 'Word2Vec': {'Linear SVM': 0.6028301886792452,\n",
      "              'Logistic Regression': 0.6132075471698114,\n",
      "              'Random Forest': 0.6632075471698113,\n",
      "              'XGBoost': 0.6632075471698113}}\n"
     ]
    }
   ],
   "source": [
    "pprint(dict_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac2c4d-831d-4174-a724-dd4e4d0478ca",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df5b07-8d1b-4276-9375-e3f87bb068fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    params_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec1671-1a14-483c-b316-73fb5bac4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478278c0-3a30-47f2-a4df-84dfe4aad081",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(grid_search.best_estimator_,\n",
    "            \"../models/tfidf_logreg_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
