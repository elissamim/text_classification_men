{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c7fd5b-99c0-4ec6-8c1a-bc724a8c1263",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20976841-f12e-4575-9e65-df53e3096ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import fireducks.pandas as pd\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from ml_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bfede60-9124-4c0f-a243-684e52391db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "fs = s3fs.S3FileSystem(\n",
    "            client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"},\n",
    "            key=os.environ[\"Accesskey\"],\n",
    "            secret=os.environ[\"Secretkey\"],\n",
    "            token=os.environ[\"Token\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfefd20-d69c-46de-8d59-67096ab8b371",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5e87e5-7b6a-4f1d-8fa1-d429f5cbdc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_text</th>\n",
       "      <th>sol</th>\n",
       "      <th>clean_phrase_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>* Aider à la mise en place de l évènement Shar...</td>\n",
       "      <td>0</td>\n",
       "      <td>aider mise place évènemer shareplan envoi rapp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* Comprendre le métier des achats * Comment or...</td>\n",
       "      <td>0</td>\n",
       "      <td>comprendre métier achat comment organiser appe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* Fendre du bois en forêt au merlin manuelleme...</td>\n",
       "      <td>0</td>\n",
       "      <td>fendre boi forêt merlin manuellemer débarder b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 jours au CDI , 1 jour en arts plastiques , 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>2 jour cdi 1 jour art plastique 1 jour musiqu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 jours au sein du Bureau des affaires institu...</td>\n",
       "      <td>1</td>\n",
       "      <td>4 jour sein bureau affaire institutionnel fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with fs.open(\"elissamim/text_classification_men/data/stages-votes.json\", \"r\") as file:\n",
    "    df = pd.read_json(file)\n",
    "\n",
    "df = df.groupby(\"phrase_text\", as_index = False)[\"sol\"].apply(lambda x: x.mode().iloc[0])\n",
    "df[\"sol\"]=df[\"sol\"].apply(lambda x: 1 if x == \"ok\" else 0)\n",
    "df[\"clean_phrase_text\"] = df[\"phrase_text\"].apply(lambda x: nltk_text_preprocessing(x, True))\n",
    "df = df[df[\"clean_phrase_text\"] != \"\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e3346-d25a-4e73-a41d-2b4eb7cd41aa",
   "metadata": {},
   "source": [
    "# Model (static embedding (sparse or dense) + classification algorithm) pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "071f8ae2-9587-4608-a156-ba67eb9896c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Static embeddings:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Classification algorithms:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Classification algorithms:  20%|██        | 1/5 [00:02<00:10,  2.60s/it]\u001b[A\n",
      "Classification algorithms:  40%|████      | 2/5 [00:23<00:39, 13.20s/it]\u001b[A\n",
      "Classification algorithms:  60%|██████    | 3/5 [00:38<00:28, 14.19s/it]\u001b[A\n",
      "Classification algorithms:  80%|████████  | 4/5 [00:40<00:09,  9.43s/it]\u001b[A\n",
      "Classification algorithms: 100%|██████████| 5/5 [01:28<00:00, 17.62s/it]\u001b[A\n",
      "Static embeddings:  20%|██        | 1/5 [01:28<05:52, 88.12s/it]\n",
      "Classification algorithms:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Classification algorithms:  20%|██        | 1/5 [00:02<00:08,  2.07s/it]\u001b[A\n",
      "Classification algorithms:  40%|████      | 2/5 [00:21<00:36, 12.08s/it]\u001b[A\n",
      "Classification algorithms:  60%|██████    | 3/5 [00:34<00:25, 12.78s/it]\u001b[A\n",
      "Classification algorithms:  80%|████████  | 4/5 [00:36<00:08,  8.58s/it]\u001b[A\n",
      "Classification algorithms: 100%|██████████| 5/5 [01:15<00:00, 15.08s/it]\u001b[A\n",
      "Static embeddings:  40%|████      | 2/5 [02:43<04:01, 80.64s/it]\n",
      "Classification algorithms:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Classification algorithms:  20%|██        | 1/5 [00:02<00:08,  2.13s/it]\u001b[A\n",
      "Classification algorithms:  40%|████      | 2/5 [00:20<00:35, 11.81s/it]\u001b[A\n",
      "Classification algorithms:  60%|██████    | 3/5 [00:34<00:25, 12.66s/it]\u001b[A\n",
      "Classification algorithms:  80%|████████  | 4/5 [00:36<00:08,  8.48s/it]\u001b[A\n",
      "Classification algorithms: 100%|██████████| 5/5 [01:03<00:00, 12.77s/it]\u001b[A\n",
      "Static embeddings:  60%|██████    | 3/5 [03:47<02:25, 72.98s/it]\n",
      "Classification algorithms:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Classification algorithms:  20%|██        | 1/5 [00:23<01:32, 23.07s/it]\u001b[A\n",
      "Classification algorithms:  40%|████      | 2/5 [00:43<01:03, 21.29s/it]\u001b[A\n",
      "Classification algorithms:  60%|██████    | 3/5 [01:30<01:06, 33.38s/it]\u001b[A\n",
      "Classification algorithms: 100%|██████████| 5/5 [02:10<00:00, 26.15s/it]\u001b[A\n",
      "Static embeddings:  80%|████████  | 4/5 [05:58<01:35, 95.78s/it]\n",
      "Classification algorithms:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Classification algorithms:  20%|██        | 1/5 [00:22<01:30, 22.63s/it]\u001b[A\n",
      "Classification algorithms:  40%|████      | 2/5 [00:51<01:18, 26.22s/it]\u001b[A\n",
      "Classification algorithms:  60%|██████    | 3/5 [03:20<02:44, 82.14s/it]\u001b[A\n",
      "Classification algorithms: 100%|██████████| 5/5 [04:08<00:00, 49.68s/it]\u001b[A\n",
      "Static embeddings: 100%|██████████| 5/5 [10:06<00:00, 121.30s/it]\n"
     ]
    }
   ],
   "source": [
    "X = df[\"clean_phrase_text\"]\n",
    "y = df[\"sol\"]\n",
    "\n",
    "tokenized_texts = [text.split() for text in df[\"clean_phrase_text\"]]\n",
    "word2vec_model = Word2Vec(sentences = tokenized_texts,\n",
    "                         vector_size = 100,\n",
    "                         window = 5,\n",
    "                         min_count = 1,\n",
    "                         workers = 4,\n",
    "                         seed = 42)\n",
    "fasttext_model = FastText(sentences = tokenized_texts,\n",
    "                         vector_size = 100,\n",
    "                         window = 5,\n",
    "                         min_count = 1,\n",
    "                         workers = 4,\n",
    "                         seed = 42)\n",
    "\n",
    "static_embedding_models = {\n",
    "    # Sparse embeddings\n",
    "    \"Bag of Words\":CountVectorizer(),\n",
    "    \"TF\":TfidfVectorizer(use_idf=False, norm = \"l1\"),\n",
    "    \"TF-IDF\":TfidfVectorizer(),\n",
    "    # Dense embeddings\n",
    "    \"Word2Vec\": MeanEmbeddingVectorizer(model=word2vec_model),\n",
    "    \"FastText\": MeanEmbeddingVectorizer(model=fasttext_model)\n",
    "}\n",
    "\n",
    "classification_models = {\n",
    "    \"Logistic Regression\":LogisticRegression(),\n",
    "    \"Random Forest\":RandomForestClassifier(),\n",
    "    \"Linear SVM\":SVC(kernel=\"linear\", probability=True),\n",
    "    \"Multinomial Naive Bayes\":MultinomialNB(),\n",
    "    \"XGBoost\":XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "dict_scores = {}\n",
    "\n",
    "for embedding_name, embedding_model in tqdm(static_embedding_models.items(),\n",
    "                                           desc=\"Static embeddings\"):\n",
    "\n",
    "    dict_scores[embedding_name] = {}\n",
    "    \n",
    "    for classification_name, classification_model in tqdm(classification_models.items(),\n",
    "                                                         desc=\"Classification algorithms\"):\n",
    "\n",
    "        # Multinomial NB is not suited for dense vectors\n",
    "        if embedding_name in [\"Word2Vec\", \"FastText\"] and classification_name == \"Multinomial Naive Bayes\":\n",
    "            continue\n",
    "\n",
    "        # For Logistic Regression and Linear SVM, and for dense embeddings, add standardisation\n",
    "        if embedding_name in [\"Word2Vec\", \"FastText\"] and classification_name in [\"Logistic Regression\", \"Linear SVM\"]:\n",
    "\n",
    "            pipeline = Pipeline(\n",
    "                [\n",
    "                    (\"feature_extraction\", embedding_model),\n",
    "                    (\"standardisation\", StandardScaler()),\n",
    "                    (\"classifier\", classification_model)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        else:\n",
    "        \n",
    "            pipeline = Pipeline(\n",
    "                [\n",
    "                    (\"feature_extraction\", embedding_model),\n",
    "                    (\"classifier\", classification_model)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        scores = cross_val_score(pipeline, X, y, cv=10, scoring=\"accuracy\")\n",
    "\n",
    "        dict_scores[embedding_name][classification_name] = f\"{np.mean(scores):.3f} ± {np.std(scores):.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8527d47-bd23-43a4-8d50-7ba0327a0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bag of Words': {'Linear SVM': '0.609 ± 0.023',\n",
      "                  'Logistic Regression': '0.655 ± 0.029',\n",
      "                  'Multinomial Naive Bayes': '0.614 ± 0.052',\n",
      "                  'Random Forest': '0.638 ± 0.033',\n",
      "                  'XGBoost': '0.635 ± 0.023'},\n",
      " 'FastText': {'Linear SVM': '0.607 ± 0.002',\n",
      "              'Logistic Regression': '0.594 ± 0.028',\n",
      "              'Random Forest': '0.595 ± 0.027',\n",
      "              'XGBoost': '0.576 ± 0.042'},\n",
      " 'TF': {'Linear SVM': '0.605 ± 0.012',\n",
      "        'Logistic Regression': '0.604 ± 0.019',\n",
      "        'Multinomial Naive Bayes': '0.606 ± 0.004',\n",
      "        'Random Forest': '0.649 ± 0.018',\n",
      "        'XGBoost': '0.651 ± 0.040'},\n",
      " 'TF-IDF': {'Linear SVM': '0.629 ± 0.033',\n",
      "            'Logistic Regression': '0.659 ± 0.032',\n",
      "            'Multinomial Naive Bayes': '0.621 ± 0.024',\n",
      "            'Random Forest': '0.646 ± 0.020',\n",
      "            'XGBoost': '0.623 ± 0.036'},\n",
      " 'Word2Vec': {'Linear SVM': '0.597 ± 0.034',\n",
      "              'Logistic Regression': '0.591 ± 0.033',\n",
      "              'Random Forest': '0.643 ± 0.031',\n",
      "              'XGBoost': '0.612 ± 0.043'}}\n"
     ]
    }
   ],
   "source": [
    "pprint(dict_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1eb29-9b07-40df-84a6-28c58376ac15",
   "metadata": {},
   "source": [
    "Best model is TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac2c4d-831d-4174-a724-dd4e4d0478ca",
   "metadata": {},
   "source": [
    "# Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df5b07-8d1b-4276-9375-e3f87bb068fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "params_grid = {\n",
    "    \"tfidf__max_df\":[.7, .8, .9, 1],\n",
    "    \"tfidf__min_df\":[.001, .01, .1],\n",
    "    \"tfidf__norm\":[\"l1\", \"l2\", None],\n",
    "    \"tfidf__sublinear_tf\":[True, False],\n",
    "    \"tfidf__max_features\":[10, 100, 1000, 10000],\n",
    "    \"tfidf__ngram_range\":[]\n",
    "    \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    params_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
