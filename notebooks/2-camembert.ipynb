{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6b8d3d-313d-4110-8e7e-c432b5dd6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d5f164-1887-4c04-86d3-8a23536e35de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import s3fs\n",
    "import sys\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import fireducks.pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import (\n",
    "                        CamembertTokenizer,\n",
    "                        CamembertForSequenceClassification,\n",
    "                        Trainer,\n",
    "                        TrainingArguments\n",
    "                        )\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from ml_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c57e05e-5c63-47ba-b21b-7a111e2a3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "fs = s3fs.S3FileSystem(\n",
    "            client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"},\n",
    "            key=os.environ[\"Accesskey\"],\n",
    "            secret=os.environ[\"Secretkey\"],\n",
    "            token=os.environ[\"Token\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcb4bb5-473b-48ef-af3c-cbe01f1ae3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_text</th>\n",
       "      <th>sol</th>\n",
       "      <th>clean_phrase_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>* Aider à la mise en place de l évènement Shar...</td>\n",
       "      <td>0</td>\n",
       "      <td>aider mise place évènemer shareplan envoi rapp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* Comprendre le métier des achats * Comment or...</td>\n",
       "      <td>0</td>\n",
       "      <td>comprendre métier achat comment organiser appe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* Fendre du bois en forêt au merlin manuelleme...</td>\n",
       "      <td>0</td>\n",
       "      <td>fendre boi forêt merlin manuellemer débarder b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 jours au CDI , 1 jour en arts plastiques , 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>2 jour cdi 1 jour art plastique 1 jour musiqu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 jours au sein du Bureau des affaires institu...</td>\n",
       "      <td>1</td>\n",
       "      <td>4 jour sein bureau affaire institutionnel fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with fs.open(\"elissamim/text_classification_men/data/stages-votes.json\", \"r\") as file:\n",
    "    df = pd.read_json(file)\n",
    "\n",
    "df = df.groupby(\"phrase_text\", as_index = False)[\"sol\"].apply(lambda x: x.mode().iloc[0])\n",
    "df[\"sol\"]=df[\"sol\"].apply(lambda x: 1 if x == \"ok\" else 0)\n",
    "df[\"clean_phrase_text\"] = df[\"phrase_text\"].apply(lambda x: nltk_text_preprocessing(x, True))\n",
    "df = df[df[\"clean_phrase_text\"] != \"\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6815791-201f-4a35-84d8-f638af0ab70d",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "899692e0-0014-4bf4-9d69-049f04d7f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[\"clean_phrase_text\"].tolist(),\n",
    "    df[\"sol\"].tolist(),\n",
    "    test_size=.2,\n",
    "    stratify=df[\"sol\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# We use CamemBERT Tokenizer (Byte-Level BPE) with truncation to 512 tokens and add [PAD] tokens for sequences that are too short\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\",\n",
    "                                              do_lower_case=True)\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# We define the dataset class for PyTorch model fine-tuning\n",
    "class ClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: torch.tensor(val[idx])\n",
    "            for key, val in self.encodings.items()\n",
    "        } | {\"labels\": torch.tensor(self.labels[idx])}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ClassificationDataset(train_encodings, y_train)\n",
    "val_dataset = ClassificationDataset(val_encodings, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f55fc0-9db6-4e9c-90c0-8ca8fcf35e9e",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fb6229-f2d8-49c9-8568-e28b7617998e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-05-02 11:02:42,532] A new study created in memory with name: no-name-ef1883d9-5005-4cd0-a046-a0da1d516948\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='335' max='335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [335/335 01:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='340' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 09:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 11:04:02,101] Trial 0 finished with value: 0.6992481203007519 and parameters: {'learning_rate': 1.1829987925713312e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.10529155358099171, 'warmup_steps': 38}. Best is trial 0 with value: 0.6992481203007519.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [532/532 01:16, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.604000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 11:05:22,531] Trial 1 finished with value: 0.706766917293233 and parameters: {'learning_rate': 2.5526459319370905e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 8, 'weight_decay': 0.03400533690760766, 'warmup_steps': 352}. Best is trial 1 with value: 0.706766917293233.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='201' max='201' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [201/201 00:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 11:06:13,761] Trial 2 finished with value: 0.631578947368421 and parameters: {'learning_rate': 3.5590103952229653e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.1221796142950218, 'warmup_steps': 375}. Best is trial 1 with value: 0.706766917293233.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='335' max='335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [335/335 01:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 11:07:37,688] Trial 3 finished with value: 0.6917293233082706 and parameters: {'learning_rate': 2.7851416451301224e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.134319158579845, 'warmup_steps': 407}. Best is trial 1 with value: 0.706766917293233.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='136' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [136/136 00:56, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 11:08:38,995] Trial 4 finished with value: 0.7180451127819549 and parameters: {'learning_rate': 3.508041813680323e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.07105827435264765, 'warmup_steps': 209}. Best is trial 4 with value: 0.7180451127819549.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 01:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 11:09:54,403] Trial 5 finished with value: 0.6616541353383458 and parameters: {'learning_rate': 2.3975468903234254e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'weight_decay': 0.2832071864568592, 'warmup_steps': 429}. Best is trial 4 with value: 0.7180451127819549.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 11:10:41,419] Trial 6 finished with value: 0.6052631578947368 and parameters: {'learning_rate': 2.5025259904991174e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 32, 'weight_decay': 0.28207299911384626, 'warmup_steps': 335}. Best is trial 4 with value: 0.7180451127819549.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='136' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [136/136 00:57, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 11:11:42,730] Trial 7 finished with value: 0.6691729323308271 and parameters: {'learning_rate': 2.451159948130985e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.14231984381092444, 'warmup_steps': 349}. Best is trial 4 with value: 0.7180451127819549.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 01:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 11:12:58,001] Trial 8 finished with value: 0.6992481203007519 and parameters: {'learning_rate': 1.6638563488023205e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'weight_decay': 0.27853336038394677, 'warmup_steps': 234}. Best is trial 4 with value: 0.7180451127819549.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='136' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [136/136 00:56, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 11:13:59,207] Trial 9 finished with value: 0.6917293233082706 and parameters: {'learning_rate': 4.890531391464383e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.1426052713647916, 'warmup_steps': 187}. Best is trial 4 with value: 0.7180451127819549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "BestRun(run_id='4', objective=0.7180451127819549, hyperparameters={'learning_rate': 3.508041813680323e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.07105827435264765, 'warmup_steps': 209}, run_summary=None)\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "# Define the search space for Optuna\n",
    "def model_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 3, 5),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32]),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3),\n",
    "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\", 0, 500),\n",
    "    }\n",
    "\n",
    "# Define basic training args (used as a base)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",  # Disable saving for search runs\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=False,\n",
    ")\n",
    "\n",
    "# Use the Trainer to run hyperparameter search\n",
    "trainer = Trainer(\n",
    "    model_init=lambda: CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=2),\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "best_trial = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",              \n",
    "    hp_space=model_hp_space,\n",
    "    n_trials=10                       \n",
    ")\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7a5142-0f44-42ae-8a11-9487dbc9653b",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d280f060-fc2c-4b9d-8933-cc99eb320457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='136' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [136/136 01:00, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.690100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.686500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.685400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.664700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.672800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.677000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.656800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.645500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.643200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.606700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.599100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=136, training_loss=0.6513011560720556, metrics={'train_runtime': 60.666, 'train_samples_per_second': 69.891, 'train_steps_per_second': 2.242, 'total_flos': 169953297321600.0, 'train_loss': 0.6513011560720556, 'epoch': 4.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We load the classifier : CamemBERT Head with a classification head with the number of outputs for the final layer of 2\n",
    "# The loss is then by default CrossEntropyLoss()\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", \n",
    "                                                           num_labels=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# We use the previous hyperparameters\n",
    "best_params = best_trial.hyperparameters\n",
    "\n",
    "# We define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    per_device_train_batch_size=best_params[\"per_device_train_batch_size\"],\n",
    "    num_train_epochs=best_params[\"num_train_epochs\"],\n",
    "    weight_decay=best_params[\"weight_decay\"],\n",
    "    warmup_steps=best_params[\"warmup_steps\"],\n",
    ")\n",
    "\n",
    "# We train the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "addd5fd4-4d0b-4893-86ca-7143531f7163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5859740972518921,\n",
       " 'eval_accuracy': 0.6729323308270677,\n",
       " 'eval_runtime': 1.0704,\n",
       " 'eval_samples_per_second': 248.512,\n",
       " 'eval_steps_per_second': 31.765,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b58e8-a8dc-4908-b7f8-025dd64a93b9",
   "metadata": {},
   "source": [
    "# Stockage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b581ea-8cbb-4469-b431-721e0dd0952a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/camembert_model/tokenizer_config.json',\n",
       " '../models/camembert_model/special_tokens_map.json',\n",
       " '../models/camembert_model/sentencepiece.bpe.model',\n",
       " '../models/camembert_model/added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"../models/camembert_model\")\n",
    "tokenizer.save_pretrained(\"../models/camembert_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
